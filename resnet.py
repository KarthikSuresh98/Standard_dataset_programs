import matplotlib.image as mpimg
import numpy as np
import os
from keras import utils as np_utils
from keras.models import Sequential
from keras.layers import Conv2D , MaxPooling2D , Flatten , Dropout , Dense , Input , Subtract , BatchNormalization , Activation
import keras
from keras.optimizers import SGD
from random import choice
from random import seed
import pandas as pd
from  keras.models import Model
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score
from keras.preprocessing.image import ImageDataGenerator

images = []
folder = r'/home/karthik/Documents/yalefaces'
for filename in os.listdir(folder):
    img = mpimg.imread(os.path.join(folder,filename))
    if img is not None:
        images.append(img)
X_img = np.asarray(images , dtype = np.float32)
X_img = np.reshape(np.resize(X_img , (166 , 240 , 320)) , (166,128,200,3))
df = pd.read_csv(r'/home/karthik/Documents/traininglabels.csv')
y = np.array(df['label'])
X_img , y = shuffle(X_img , y , random_state = 0)
X_1_inp = []
X_2_inp = []
y_train = []
for i in range(10000):
    seed(i)
    X_1 = choice(X_img)
    X_2 = choice(X_img)
    X_1_inp.append(X_1)
    X_2_inp.append(X_2)
    seed(i)
    y1 = choice(y)
    y2 = choice(y)
    if y1 == y2:
        y_train.append(1)
    else:
        y_train.append(0)
X_1_inp = np.asarray(X_1_inp , dtype = np.float32)
X_2_inp = np.asarray(X_2_inp , dtype = np.float32)
y = np.asarray(y_train)
X_1_inp = X_1_inp/255.0
X_1_inp = X_1_inp/255.0
y = np.reshape(y , (y.shape[0] , 1))
X_train_1 = X_1_inp[0:9500]
X_train_2 = X_2_inp[0:9500]
y_train = y[0:9500]
X_test_1 = X_1_inp[9500:10000]
X_test_2 = X_2_inp[9500:10000]
y_test = y[9500:10000]

def resnet1(X_t_1 , X_t_2 , y_t , X_te_1 , X_te_2):

    inp1 = Input(shape = (128,200,3))  
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp1)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(x)
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(x)
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    x = Flatten()(x)

    inp2 = Input(shape = (128,200,3))
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp2)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(z)
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(z)
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    z = Flatten()(z)

    f_inp = keras.layers.Subtract()([x , z])
    f_inp = Dropout(0.3)(f_inp)
    output = Dense(1 , activation = 'sigmoid')(f_inp)
    model = Model(inputs = [inp1 , inp2] , outputs = output)
    sgd = SGD(lr = 0.005 , momentum = 0.9 , decay = 1e-4 , nesterov = True)
    model.compile(loss = 'mean_squared_logarithmic_error' , optimizer = sgd , metrics = ['accuracy'])
    model.fit([X_t_1 , X_t_2] , y_t , batch_size = 32 , epochs = 3)
    y_pred = model.predict([X_te_1 , X_te_2])
    return y_pred


def resnet2(X_t_1 , X_t_2 , y_t , X_te_1 , X_te_2):

    inp1 = Input(shape = (128,200,3))  
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp1)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(x)
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(x)
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    x = Flatten()(x)

    inp2 = Input(shape = (128,200,3))
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp2)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(z)
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(z)
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    z = Flatten()(z)
    f_inp = keras.layers.Subtract()([x , z])
    f_inp = Dropout(0.3)(f_inp)
    output = Dense(1 , activation = 'sigmoid')(f_inp)
    model = Model(inputs = [inp1 , inp2] , outputs = output)
    sgd = SGD(lr = 0.005 , momentum = 0.9 , decay = 1e-4 , nesterov = True)
    datagen = ImageDataGenerator(rotation_range = 5)
    datagen.fit(X_t_1)
    datagen.fit(X_t_2)
    model.compile(loss = 'mean_squared_logarithmic_error' , optimizer = sgd , metrics = ['accuracy'])
    model.fit_generator(datagen.flow([X_t_1 , X_t_2] , y_t , batch_size = 32) , epochs = 3)
    y_pred = model.predict([X_te_1 , X_te_2])
    return y_pred


def resnet3(X_t_1 , X_t_2 , y_t , X_te_1 , X_te_2):

    inp1 = Input(shape = (128,200,3))  
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp1)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(x)
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(x)
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    x = Flatten()(x)

    inp2 = Input(shape = (128,200,3))
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp2)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(z)
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(z)
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    z = Flatten()(z)
    f_inp = keras.layers.Subtract()([x , z])
    f_inp = Dropout(0.3)(f_inp)
    output = Dense(1 , activation = 'sigmoid')(f_inp)
    model = Model(inputs = [inp1 , inp2] , outputs = output)
    sgd = SGD(lr = 0.005 , momentum = 0.9 , decay = 1e-4 , nesterov = True)
    datagen = ImageDataGenerator(horizontal_flip = True)
    datagen.fit(X_t_1)
    datagen.fit(X_t_2)
    model.compile(loss = 'mean_squared_logarithmic_error' , optimizer = sgd , metrics = ['accuracy'])
    model.fit_generator(datagen.flow([X_t_1 , X_t_2] , y_t , batch_size = 32) , epochs = 3)
    y_pred = model.predict([X_te_1 , X_te_2])
    return y_pred


def resnet4(X_t_1 , X_t_2 , y_t , X_te_1 , X_te_2):

    inp1 = Input(shape = (128,200,3))  
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp1)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(x)
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(x)
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    res_add = x
    x = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(x)
    x = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(x)
    x = keras.layers.Add()([x , res_add])
    x = Activation('relu')(x)
    x = BatchNormalization(axis = 3)(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    x = Flatten()(x)

    inp2 = Input(shape = (128,200,3))
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(inp2)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(32 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(32 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(64 , (1,1) , activation = 'linear')(z)
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(64 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(64 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = Conv2D(128 , (1,1) , activation = 'linear')(z)
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    res_add = z
    z = Conv2D(128 , (3,3) , activation = 'relu' , padding = 'same')(z)
    z = Conv2D(128 , (3,3) , activation = 'linear' , padding = 'same')(z)
    z = keras.layers.Add()([z , res_add])
    z = Activation('relu')(z)
    z = BatchNormalization(axis = 3)(z)
    z = MaxPooling2D(pool_size = (2,2))(z)
    z = Flatten()(z)
    f_inp = keras.layers.Subtract()([x , z])
    f_inp = Dropout(0.3)(f_inp)
    output = Dense(1 , activation = 'sigmoid')(f_inp)
    model = Model(inputs = [inp1 , inp2] , outputs = output)
    sgd = SGD(lr = 0.005 , momentum = 0.9 , decay = 1e-4 , nesterov = True)
    datagen = ImageDataGenerator(width_shift_range = 0.1 , height_shift_range  = 0.1)
    datagen.fit(X_t_1)
    datagen.fit(X_t_2)
    model.compile(loss = 'mean_squared_logarithmic_error' , optimizer = sgd , metrics = ['accuracy'])
    model.fit_generator(datagen.flow([X_t_1 , X_t_2] , y_t , batch_size = 32) , epochs = 3)
    y_pred = model.predict([X_te_1 , X_te_2])
    return y_pred


y_res1 = resnet1(X_train_1 , X_train_2 , y_train , X_test_1 , X_test_2) + resnet1(X_train_1 , X_train_2 , y_train , X_test_1 , X_test_2)
y_res2 = resnet2(X_train_1 , X_train_2 , y_train , X_test_1 , X_test_2)
y_res3 = resnet3(X_train_1 , X_train_2 , y_train , X_test_1 , X_test_2)
y_res4 = resnet4(X_train_1 , X_train_2 , y_train , X_test_1 , X_test_2)
y_res = (y_res1 + y_res2 + y_res3 + y_res4)/5
Y_res = y_res.argmax(axis = -1)
print(accuracy_score(Y_res , y_test))


